{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77000c98",
   "metadata": {},
   "source": [
    "#                                            Application for Project Developer\n",
    "\n",
    "## __Statment of Interest:__\n",
    "\n",
    "I'm sure it'll come as no surprise that as a student studying LSE's new BSc Data Science program, Data Science is something I enjoy pursuing both recreationally and academically. Unfortunately, there is limited opportunity to participate in a collaborative application of data science this side of University beyond environments like Kaggle. Over summer I have worked on personal projectâ€™s immediately following on from Computer Science coursework meaning I already invest the expected time commitment into coding regardless and would be more than happy to focus this time into the Data Science Society.  The chance to pursue a structured body of work in the vein of what can be expected in a proffesional environment would be a fantastic way for me to direct and apply my passions for coding & statistics to something more practically enriching.\n",
    "\n",
    "## __Relevant Skills__\n",
    "\n",
    "I have been coding in python since GCSE (Late year 9) and have experience in machine learning which formed a large part of my coursework using machine learning to  compare ML models on predictions of bird population patterns with relation to climate change in the UK and vice versa, visualising the data in several ways including on an interactive map. This coursework formed 20% of my final grade which was an A*. Over summer I have been using Kaggle to further my skills and knowledge of Python with regards to data science by preprocessing data for applications in machine learning with one-hot-encoding, missing data handling,Exploratory Data Analysis, principle componant analysis, mutual information scores and eigen-values/vectors.\n",
    "\n",
    "\n",
    "The following are relevant excerpts from my coursework and other personal projects demonstrating use of the requisite skills:\n",
    "\n",
    "\n",
    "* Shown Below are the libraries imported for my coursework including scikit-learn for ML, pandas for data managment and seaborn/matplotlib/plotly for data visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc3871",
   "metadata": {},
   "source": [
    "* My application of scikit-learn is shown here, the program gave users the option to compare the efficacy of customisable ML models or use preset values (Chosen by input 1 or 2). This function initialised the models and returned them for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLModels(inp):\n",
    "    modelsList = []\n",
    "    if inp == 2:\n",
    "        l_regression = linear_model.LinearRegression()\n",
    "        l_ridge = linear_model.Ridge()\n",
    "        PF = make_pipeline(PolynomialFeatures(degree=2), linear_model.Ridge())\n",
    "        svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "        desc_tr = DecisionTreeRegressor(max_depth=5)\n",
    "        knn = KNeighborsRegressor(n_neighbors=7)\n",
    "        gbr = GradientBoostingRegressor(loss='ls', learning_rate=0.05, max_depth=4, min_samples_leaf=5,\n",
    "                                        min_samples_split=2,\n",
    "                                        n_estimators=100, random_state=30)\n",
    "\n",
    "        modelsList.append(l_regression)\n",
    "        modelsList.append(l_ridge)\n",
    "        modelsList.append(PF)\n",
    "        modelsList.append(svr_rbf)\n",
    "        modelsList.append(desc_tr)\n",
    "        modelsList.append(knn)\n",
    "        modelsList.append(gbr)\n",
    "\n",
    "        return modelsList\n",
    "    else:\n",
    "        # No Parameters needed\n",
    "        l_regression = linear_model.LinearRegression()\n",
    "        l_ridge = linear_model.Ridge()\n",
    "\n",
    "        # PolyRidge\n",
    "        print('Enter Polynomial Feature degree: ')\n",
    "        value = int(input())\n",
    "        PF = make_pipeline(PolynomialFeatures(degree=value), linear_model.Ridge())\n",
    "\n",
    "        # SVR\n",
    "        print('Enter gamma value for Support Vector Regression')\n",
    "        value = float(input())\n",
    "        svr_rbf = SVR(kernel='rbf', C=1e3, gamma=value)\n",
    "\n",
    "        # Decision Tree Regressor\n",
    "        print('Enter Max Depth for Decision tree Regressor')\n",
    "        value = int(input())\n",
    "        desc_tr = DecisionTreeRegressor(max_depth=value)\n",
    "\n",
    "        # KNN\n",
    "        print('Enter neighbor parameters for KNN')\n",
    "        value = int(input())\n",
    "        knn = KNeighborsRegressor(n_neighbors=value)\n",
    "\n",
    "        # GBR\n",
    "        print('Enter GBR learing rate')\n",
    "        gbr_LR = float(input())\n",
    "        print('Enter GBR max depth')\n",
    "        gbr_MD = int(input())\n",
    "        print('Enter GBR Min Samples')\n",
    "        gbr_MS = int(input())\n",
    "        print('Enter GBR Min splits')\n",
    "        gbr_MSp = int(input())\n",
    "        print('Enter Estimators')\n",
    "        gbr_NEst = int(input())\n",
    "        print('Enter Random states')\n",
    "        gbr_RandState = int(input())\n",
    "\n",
    "        gbr = GradientBoostingRegressor(loss='ls', learning_rate=gbr_LR, max_depth=gbr_MD, min_samples_leaf=gbr_MS,\n",
    "                                        min_samples_split=gbr_MSp,\n",
    "                                        n_estimators=gbr_NEst, random_state=gbr_RandState)\n",
    "        modelsList.append(l_regression)\n",
    "        modelsList.append(l_ridge)\n",
    "        modelsList.append(PF)\n",
    "        modelsList.append(svr_rbf)\n",
    "        modelsList.append(desc_tr)\n",
    "        modelsList.append(knn)\n",
    "        modelsList.append(gbr)\n",
    "\n",
    "        return modelsList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8cb809",
   "metadata": {},
   "source": [
    "* Example Comparisons made using matplotlib/seaborn/pyplot are shown here\n",
    "\n",
    "1) The [PMCC scatter plot](https://i.imgur.com/XdtQkfk.png) detailing variable correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMCC(df):\n",
    "    # Finds values for Correlations between all columns of dataframe\n",
    "    # Rounds them to 3dp for readability\n",
    "    dfPMCC = df.corr().round(3)\n",
    "    # Plots correlation Values on heatmap\n",
    "    pyplot.figure(figsize=(10, 10))\n",
    "    sns.heatmap(data=dfPMCC, annot=True)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc713c",
   "metadata": {},
   "source": [
    "2) The [relationships between](https://i.imgur.com/0c2eAXa.png) user defined target and predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7be0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y, pList):\n",
    "    # Creates plots of each x variable selected, with size\n",
    "    # relative to how many variables chosen\n",
    "    fig, axs = pyplot.subplots(ncols=len(pList), nrows=1, figsize=(20, 10))\n",
    "    axs = axs.flatten()\n",
    "    # Fills plots with Data\n",
    "    for i, k in enumerate(pList):\n",
    "        sns.regplot(y=y, x=x[k], ax=axs[i])\n",
    "    # Establishes display parameters\n",
    "    pyplot.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118cea7",
   "metadata": {},
   "source": [
    "3) The [effectiveness of each model compared](https://imgur.com/Ejz40Lx) on a  boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14080b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(list,x,y,kf):\n",
    "    \n",
    "    scores_map = {}\n",
    "        for i in list:\n",
    "            scores = cross_val_score(i, x, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "            scores_map[str(i)] = scores\n",
    "\n",
    "        pyplot.figure(figsize=(20, 10))\n",
    "        scores_map = pd.DataFrame(scores_map)\n",
    "        sns.boxplot(data=scores_map)\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cd0a5",
   "metadata": {},
   "source": [
    "4) An [interactive map](https://imgur.com/YqDVkoO) displaying the target variable with ML predictions for the users inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mapper(data, x, y, key):\n",
    "    # Plotly mapper requires size value - hence list equal in length to original\n",
    "    # dataframe + user entries\n",
    "    sizeList = []\n",
    "    for i in range(0, (len(data))):\n",
    "        sizeList.append(15)\n",
    "    # size list appended to dataframe\n",
    "    data.insert(1, 'Size', sizeList, True)\n",
    "    #  Figure created with relevant data\n",
    "    fig = px.scatter_mapbox(data, lat='Lat', lon='Long', color=data.index, zoom=5, size='Size', hover_name=y,\n",
    "                            hover_data=x)\n",
    "    # Access Token from mapbox account passed to authorise mapping\n",
    "    fig.update_layout(mapbox_style=\"light\", mapbox_accesstoken=key)\n",
    "    # Figure Displayed\n",
    "    fig.show(config={\"displayModeBar\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb53db",
   "metadata": {},
   "source": [
    "* Application of ML Models to generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputPredictions(df, model, y):\n",
    "    # Initialise Variables\n",
    "    varList = []\n",
    "    inp_dict = {}\n",
    "    pList = []\n",
    "    BigPList = []\n",
    "    # Adding variable Headers to list\n",
    "    for i in df:\n",
    "        varList.append(i)\n",
    "\n",
    "    # Removing unnecessary data instances that do not require user input\n",
    "    varList.remove('Year')\n",
    "    varList.remove('Long')\n",
    "    varList.remove('Lat')\n",
    "    varList.remove(y)\n",
    "    # Getting user input for number of additional entries\n",
    "    print('How many y values would you like to predict for')\n",
    "    inpCount = int(numericalInp())\n",
    "    # Iterates through user selected predictor variables\n",
    "    # Creating a dictionary entry for each entry\n",
    "    for i in range(0, inpCount):\n",
    "        # Assigns a value to the year varible to denote difference\n",
    "        for i in varList:\n",
    "            print('Enter', i, 'Value')\n",
    "            userInp = numericalInp()\n",
    "            pList.append(userInp)\n",
    "            inp_dict[i] = userInp\n",
    "        # Predict function takes an array hence array placed in array\n",
    "        BigPList.append(pList)\n",
    "        prediction = model.predict(BigPList)\n",
    "\n",
    "        inp_dict[y] = round(prediction[0], 2)\n",
    "        # Create random location data for mapping visualisation function\n",
    "        inp_dict['Long'] = random.randrange(-300, 50) / 100\n",
    "        inp_dict['Lat'] = random.randrange(5100, 5400) / 100\n",
    "        inp_dict['Year'] = 'Future'\n",
    "        # Appends dictionary to dataframe\n",
    "        df = df.append(inp_dict, ignore_index=True)\n",
    "        # Resets addition variables for next set\n",
    "        inp_dict = {}\n",
    "        pList = []\n",
    "        BigPList = []\n",
    "\n",
    "    return df\n",
    "\n",
    "finalModel = modelList[choice - 1]\n",
    "finalModel.fit(x, y)\n",
    "\n",
    "mappingDF = InputPredictions(df, finalModel, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d4625",
   "metadata": {},
   "source": [
    "* Additionally I have experience in data collection from my coursework and other projects. Below is evidence of two instaces of API interfacing to collect data from eBird (for my coursework) as well as Spotify (for a personal project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9085e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eBird Data Collection\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def jconvert(obj):\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)  # Converts the json from request to a more readable format\n",
    "    return text  # Returns JSON for furthur analysis\n",
    "\n",
    "\n",
    "def jprint(obj):\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)  # Converts the json from request to a more readable format\n",
    "    print(text)  # Prints text to user (More used in testing)\n",
    "\n",
    "\n",
    "def eBird_get(date, location):\n",
    "    api_token = 'ouseefqn70nk'  # API Token from ebird site\n",
    "    headers = {'x-ebirdapitoken': api_token}  # Attatching token to request\n",
    "    url = str(\n",
    "        'https://api.ebird.org/v2/data/obs/' + location + '/historic/' + date)  # Defining URL with user parameters\n",
    "    r = requests.get(url, headers=headers)  # Making Request\n",
    "    return r.json()  # Returning json to be converted to a more readable format\n",
    "\n",
    "\n",
    "def birdCount(start_year, end_year):\n",
    "    start_date = datetime.date(start_year, 1, 1)  # Defines Start Date\n",
    "    delta = datetime.timedelta(days=1)  # Defines increment\n",
    "    query_date = str(start_date).replace('-', '/')  # Converts to API format\n",
    "    bCount = 0  # Initialise count variable\n",
    "\n",
    "    for i in range(start_year, end_year): # Iterate Through Years\n",
    "        for j in range(1, 12): # Iterate Through months\n",
    "            for k in range(1, 28): # Iterate Through average number of days\n",
    "                for l in range(1, 20): # Iterate through species sightings in a day\n",
    "                    bCount += eBird_get(query_date, locCode)[l]['howMany'] # Update total number of birds seen\n",
    "                    start_date += delta # Increment date\n",
    "                    query_date = str(start_date).replace('-', '/') # Convert back to API date\n",
    "\n",
    "    return bCount\n",
    "\n",
    "\n",
    "locCode = input('Enter Location Code ')\n",
    "query_date = input('Enter Date ')\n",
    "\n",
    "jprint(eBird_get(query_date, locCode)[2]['howMany'])\n",
    "\n",
    "start = input('Enter Start Year ')\n",
    "end = input('Enter End Year ')\n",
    "birdCount(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API Interface\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# API Credentials\n",
    "cid = '*************'\n",
    "secret = '***************'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager= client_credentials_manager)\n",
    "\n",
    "# Converting playlist into dataframe wit spotify track metadata\n",
    "def call_playlist(creator, playlist_id):\n",
    "    playlist_features_list = [\"artist\",\"album\",\"track_name\",  \"track_id\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\", \"speechiness\",\"instrumentalness\",\"liveness\",\"valence\",\"tempo\", \"duration_ms\",\"time_signature\"]\n",
    "    playlist_df = pd.DataFrame(columns = playlist_features_list)\n",
    "    results = sp.user_playlist_tracks(creator,playlist_id)\n",
    "\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "\n",
    "    for track in tracks:\n",
    "        playlist_features = {}\n",
    "        playlist_features[\"artist\"] = track[\"track\"][\"album\"][\"artists\"][0][\"name\"]\n",
    "        playlist_features[\"album\"] = track[\"track\"][\"album\"][\"name\"]\n",
    "        playlist_features[\"track_name\"] = track[\"track\"][\"name\"]\n",
    "        playlist_features[\"track_id\"] = track[\"track\"][\"id\"]\n",
    "\n",
    "        # Get audio features\n",
    "        audio_features = sp.audio_features(playlist_features[\"track_id\"])[0]\n",
    "        for feature in playlist_features_list[4:]:\n",
    "            playlist_features[feature] = audio_features[feature]\n",
    "\n",
    "        track_df = pd.DataFrame(playlist_features, index=[0])\n",
    "        playlist_df = pd.concat([playlist_df, track_df], ignore_index=True)\n",
    "\n",
    "    return playlist_df\n",
    "\n",
    "# ID to find playlist\n",
    "\n",
    "ID = input('Enter ID ')\n",
    "name = input('Enter File Name ')+'.csv'\n",
    "playlist = call_playlist('spotify',ID).to_csv('/Users/jaggergarcia/PycharmProjects/SpotifyComp/PlaylistData/'+name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
